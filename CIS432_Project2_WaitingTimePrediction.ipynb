{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# CIS432 — Optional Project 2\n## Waiting Time Prediction in Healthcare Operations\n\n**Data:** Simulated RFID tracking data from a cancer hospital (Jan–Jun 2024)  \n**Target:** Minutes a patient waits between `examination_checkin` and `examination_start`  \n**Dataset:** 12,762 patient visits across 5 tasks\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Shared Setup\nInstall and import all required libraries, then load the data once."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import (mean_squared_error, mean_absolute_error,\n                              r2_score, mean_pinball_loss)\nfrom sklearn.dummy import DummyRegressor\n\nplt.rcParams.update({\n    'figure.facecolor': '#0f0f0f', 'axes.facecolor': '#1a1a2e',\n    'axes.edgecolor': '#333', 'axes.labelcolor': 'white',\n    'xtick.color': 'white', 'ytick.color': 'white',\n    'text.color': 'white', 'grid.color': '#333',\n    'grid.linestyle': '--', 'grid.alpha': 0.5,\n    'font.family': 'monospace',\n})\nGREEN='#00ff9f'; ORANGE='#ff9f00'; RED='#ff4444'; BLUE='#4499ff'; PURPLE='#cc88ff'"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Load Data & Feature Engineering\nAll tasks share the same base features, engineered at `examination_checkin` time."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "rt   = pd.read_excel('data.xlsx', sheet_name='realtime')\nappt = pd.read_excel('data.xlsx', sheet_name='appointments')\n\nrt['datetime']        = pd.to_datetime(rt['date'].astype(str) + ' ' + rt['time'].astype(str))\nappt['appt_datetime'] = pd.to_datetime(appt['date'].astype(str) + ' ' + appt['time'].astype(str))\n\npat = rt[rt['entity_type'] == 'patient'].copy()\nkey_events = ['hospital_checkin','bloodwork_checkin','bloodwork_start',\n              'bloodwork_end','examination_checkin','examination_start']\ndf = pat[pat['event'].isin(key_events)].pivot_table(\n    index=['entity_id','date'], columns='event',\n    values='datetime', aggfunc='first'\n).reset_index()\ndf.columns.name = None\n\ndf['wait_minutes'] = (df['examination_start'] - df['examination_checkin']).dt.total_seconds() / 60\ndf = df.dropna(subset=['wait_minutes','examination_checkin'])\n\nappt_m = appt.rename(columns={'patient_id':'entity_id'})\ndf = df.merge(appt_m[['entity_id','date','appt_datetime','provider_id']],\n              on=['entity_id','date'], how='left')\ndf = df.sort_values('examination_checkin').reset_index(drop=True)\n\ndf['checkin_hour']             = df['examination_checkin'].dt.hour\ndf['checkin_minute']           = df['examination_checkin'].dt.minute\ndf['day_of_week']              = df['examination_checkin'].dt.dayofweek\ndf['week']                     = df['examination_checkin'].dt.isocalendar().week.astype(int)\ndf['bloodwork_duration']       = (df['bloodwork_end'] - df['bloodwork_start']).dt.total_seconds() / 60\ndf['total_pre_exam_time']      = (df['examination_checkin'] - df['hospital_checkin']).dt.total_seconds() / 60\ndf['early_late_min']           = (df['examination_checkin'] - df['appt_datetime']).dt.total_seconds() / 60\ndf['queue_position']           = df.groupby('date').cumcount()\ndf['provider_patients_so_far'] = df.groupby(['date','provider_id']).cumcount()\n\nFEATURES = ['checkin_hour','checkin_minute','day_of_week','week',\n            'bloodwork_duration','total_pre_exam_time',\n            'early_late_min','queue_position','provider_patients_so_far']\nX = df[FEATURES].copy()\ny = df['wait_minutes'].copy()\n\nprint(f'Dataset: {len(X):,} samples | Target mean={y.mean():.1f} min | std={y.std():.1f} min')\ndf[['wait_minutes']].describe().round(2)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Conceptual & Operational Framing\n\n**Intended users:**  \nThe primary users are *patients* (to know how long to wait) and *clinical staff / administrators* (to manage scheduling and staffing). Predictions would be shown on a waiting-room display screen and optionally pushed to patients' phones.\n\n**Harms from prediction errors:**  \n- *Underestimation*: Patient leaves or becomes distressed when wait exceeds prediction; erodes trust.  \n- *Overestimation*: Patient may leave unnecessarily early or staff over-allocate resources.  \nAsymmetric harm suggests favouring conservative estimates — quantile q75 rather than q50 for patient-facing display.\n\n**Interpretability:**  \nInterpretability matters for staff trust and regulatory compliance. Feature importance charts (Task 1) and calibration plots (Task 3) help clinicians understand and validate the system. Black-box accuracy alone is insufficient for clinical adoption.\n\n**Deployment plan:**  \n1. Offline validation on held-out months (e.g., train Jan–Apr, test May–Jun)  \n2. Shadow mode pilot: run predictions silently alongside current operations  \n3. A/B rollout with one provider team for 4 weeks  \n4. Weekly monitoring of RMSE and coverage; monthly retraining  \n5. Full deployment with drift detection alerts\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Task 1 — Point Prediction\nA single predicted waiting time value per patient at examination check-in."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CIS432 Optional Project 2 — Task 1: Point Prediction\nWaiting Time Prediction in Healthcare Operations\n\n# ── Imports ──────────────────────────────────────────────────────────────────\n\n\n# ── Style ─────────────────────────────────────────────────────────────────────\n    \"figure.facecolor\": \"#0f0f0f\",\n    \"axes.facecolor\":   \"#1a1a2e\",\n    \"axes.edgecolor\":   \"#333\",\n    \"axes.labelcolor\":  \"white\",\n    \"xtick.color\":      \"white\",\n    \"ytick.color\":      \"white\",\n    \"text.color\":       \"white\",\n    \"grid.color\":       \"#333\",\n    \"grid.linestyle\":   \"--\",\n    \"grid.alpha\":       0.5,\n    \"font.family\":      \"monospace\",\n})\nGREEN  = \"#00ff9f\"\nRED    = \"#ff4444\"\nBLUE   = \"#4499ff\"\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 1. DATA LOADING & FEATURE ENGINEERING\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"=\" * 60)\nprint(\"TASK 1 — POINT PREDICTION\")\nprint(\"=\" * 60)\n\nrt   = pd.read_excel(\"data.xlsx\", sheet_name=\"realtime\")\nappt = pd.read_excel(\"data.xlsx\", sheet_name=\"appointments\")\n\nrt[\"datetime\"]       = pd.to_datetime(rt[\"date\"].astype(str)   + \" \" + rt[\"time\"].astype(str))\nappt[\"appt_datetime\"] = pd.to_datetime(appt[\"date\"].astype(str) + \" \" + appt[\"time\"].astype(str))\n\n# --- pivot key patient events ---\npat = rt[rt[\"entity_type\"] == \"patient\"].copy()\nkey_events = [\"hospital_checkin\",\"bloodwork_checkin\",\"bloodwork_start\",\n              \"bloodwork_end\",\"examination_checkin\",\"examination_start\"]\ndf = pat[pat[\"event\"].isin(key_events)].pivot_table(\n    index=[\"entity_id\",\"date\"], columns=\"event\",\n    values=\"datetime\", aggfunc=\"first\"\n).reset_index()\ndf.columns.name = None\n\n# --- target ---\ndf[\"wait_minutes\"] = (df[\"examination_start\"] - df[\"examination_checkin\"]).dt.total_seconds() / 60\ndf = df.dropna(subset=[\"wait_minutes\", \"examination_checkin\"])\n\n# --- merge appointments (scheduled provider, scheduled time) ---\nappt_m = appt.rename(columns={\"patient_id\": \"entity_id\"})\ndf = df.merge(appt_m[[\"entity_id\",\"date\",\"appt_datetime\",\"provider_id\"]],\n              on=[\"entity_id\",\"date\"], how=\"left\")\n\n# --- feature engineering ---\ndf = df.sort_values(\"examination_checkin\").reset_index(drop=True)\n\ndf[\"checkin_hour\"]           = df[\"examination_checkin\"].dt.hour\ndf[\"checkin_minute\"]         = df[\"examination_checkin\"].dt.minute\ndf[\"day_of_week\"]            = df[\"examination_checkin\"].dt.dayofweek     # 0=Mon\ndf[\"week\"]                   = df[\"examination_checkin\"].dt.isocalendar().week.astype(int)\ndf[\"bloodwork_duration\"]     = (df[\"bloodwork_end\"] - df[\"bloodwork_start\"]).dt.total_seconds() / 60\ndf[\"total_pre_exam_time\"]    = (df[\"examination_checkin\"] - df[\"hospital_checkin\"]).dt.total_seconds() / 60\ndf[\"early_late_min\"]         = (df[\"examination_checkin\"] - df[\"appt_datetime\"]).dt.total_seconds() / 60\ndf[\"queue_position\"]         = df.groupby(\"date\").cumcount()\ndf[\"provider_patients_so_far\"] = df.groupby([\"date\",\"provider_id\"]).cumcount()\n\nFEATURES = [\n    \"checkin_hour\", \"checkin_minute\", \"day_of_week\", \"week\",\n    \"bloodwork_duration\", \"total_pre_exam_time\",\n    \"early_late_min\", \"queue_position\", \"provider_patients_so_far\"\n]\nTARGET = \"wait_minutes\"\n\nX = df[FEATURES].copy()\ny = df[TARGET].copy()\n\nprint(f\"\\n✓ Dataset ready: {X.shape[0]:,} samples, {X.shape[1]} features\")\nprint(f\"  Target — mean: {y.mean():.1f} min | median: {y.median():.1f} min | std: {y.std():.1f} min\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 2. TARGET DISTRIBUTION\n# ═══════════════════════════════════════════════════════════════════════════════\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nfig.suptitle(\"Waiting Time Distribution\", color=GREEN, fontsize=14, fontweight=\"bold\")\n\naxes[0].hist(y, bins=50, color=GREEN, alpha=0.8, edgecolor=\"#0f0f0f\")\naxes[0].axvline(y.mean(),   color=ORANGE, linewidth=2, linestyle=\"--\", label=f\"Mean {y.mean():.1f}\")\naxes[0].axvline(y.median(), color=BLUE,   linewidth=2, linestyle=\":\",  label=f\"Median {y.median():.1f}\")\naxes[0].set_xlabel(\"Wait (minutes)\")\naxes[0].set_ylabel(\"Count\")\naxes[0].set_title(\"Distribution\")\naxes[0].legend()\naxes[0].grid(True)\n\naxes[1].hist(np.log1p(y), bins=50, color=BLUE, alpha=0.8, edgecolor=\"#0f0f0f\")\naxes[1].set_xlabel(\"log(1 + Wait)\")\naxes[1].set_ylabel(\"Count\")\naxes[1].set_title(\"Log-Transformed Distribution\")\naxes[1].grid(True)\n\nplt.tight_layout()\nplt.savefig(\"task1_target_distribution.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"\\n✓ Saved: task1_target_distribution.png\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 3. MODEL TRAINING — 5-FOLD CROSS VALIDATION\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"─\" * 60)\nprint(\"MODEL EVALUATION (5-Fold CV)\")\nprint(\"─\" * 60)\n\nmodels = {\n    \"Baseline (Mean)\":       DummyRegressor(strategy=\"mean\"),\n    \"Linear Regression\":     Pipeline([(\"scaler\", StandardScaler()), (\"model\", LinearRegression())]),\n    \"Ridge Regression\":      Pipeline([(\"scaler\", StandardScaler()), (\"model\", Ridge(alpha=1.0))]),\n    \"Decision Tree\":         DecisionTreeRegressor(max_depth=6, random_state=42),\n    \"Random Forest\":         RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1),\n    \"Gradient Boosting\":     GradientBoostingRegressor(n_estimators=200, max_depth=4, learning_rate=0.05, random_state=42),\n}\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nresults = {}\nfor name, model in models.items():\n    rmse_scores = np.sqrt(-cross_val_score(model, X, y, cv=kf, scoring=\"neg_mean_squared_error\"))\n    mae_scores  = -cross_val_score(model, X, y, cv=kf, scoring=\"neg_mean_absolute_error\")\n    r2_scores   =  cross_val_score(model, X, y, cv=kf, scoring=\"r2\")\n    results[name] = {\n        \"RMSE mean\": rmse_scores.mean(), \"RMSE std\": rmse_scores.std(),\n        \"MAE mean\":  mae_scores.mean(),  \"MAE std\":  mae_scores.std(),\n        \"R² mean\":   r2_scores.mean(),   \"R² std\":   r2_scores.std(),\n    }\n    print(f\"  {name:<25} RMSE={rmse_scores.mean():.2f}±{rmse_scores.std():.2f}  \"\n          f\"MAE={mae_scores.mean():.2f}±{mae_scores.std():.2f}  \"\n          f\"R²={r2_scores.mean():.3f}±{r2_scores.std():.3f}\")\n\nresults_df = pd.DataFrame(results).T\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 4. MODEL COMPARISON CHART\n# ═══════════════════════════════════════════════════════════════════════════════\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfig.suptitle(\"Task 1 — Model Comparison (5-Fold CV)\", color=GREEN, fontsize=14, fontweight=\"bold\")\n\nmetrics = [(\"RMSE mean\", \"RMSE std\", \"RMSE (minutes)\", RED),\n           (\"MAE mean\",  \"MAE std\",  \"MAE (minutes)\",  ORANGE),\n           (\"R² mean\",   \"R² std\",   \"R²\",             BLUE)]\n\nmodel_names = [n.replace(\" \", \"\\n\") for n in results_df.index]\n\nfor ax, (mean_col, std_col, label, color) in zip(axes, metrics):\n    bars = ax.barh(model_names, results_df[mean_col],\n                   xerr=results_df[std_col], color=color, alpha=0.8,\n                   error_kw={\"ecolor\": \"white\", \"capsize\": 4})\n    ax.set_xlabel(label)\n    ax.set_title(label)\n    ax.grid(True, axis=\"x\")\n    for bar, val in zip(bars, results_df[mean_col]):\n        ax.text(bar.get_width() + results_df[std_col].max() * 0.05,\n                bar.get_y() + bar.get_height() / 2,\n                f\"{val:.2f}\", va=\"center\", fontsize=8, color=\"white\")\n\nplt.tight_layout()\nplt.savefig(\"task1_model_comparison.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"\\n✓ Saved: task1_model_comparison.png\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 5. BEST MODEL: ACTUAL vs PREDICTED + FEATURE IMPORTANCE\n# ═══════════════════════════════════════════════════════════════════════════════\nbest_model = GradientBoostingRegressor(n_estimators=200, max_depth=4, learning_rate=0.05, random_state=42)\n\n# Collect OOF predictions\noof_pred = np.zeros(len(y))\nfor train_idx, val_idx in kf.split(X):\n    best_model.fit(X.iloc[train_idx], y.iloc[train_idx])\n    oof_pred[val_idx] = best_model.predict(X.iloc[val_idx])\n\n# Refit on full data for feature importance\nbest_model.fit(X, y)\n\nfig, axes = plt.subplots(1, 2, figsize=(13, 5))\nfig.suptitle(\"Gradient Boosting — Best Model Analysis\", color=GREEN, fontsize=14, fontweight=\"bold\")\n\n# Actual vs Predicted\nax = axes[0]\nax.scatter(y, oof_pred, alpha=0.15, s=8, color=GREEN)\nlims = [0, max(y.max(), oof_pred.max())]\nax.plot(lims, lims, \"--\", color=RED, linewidth=1.5, label=\"Perfect prediction\")\nax.set_xlabel(\"Actual Wait (min)\")\nax.set_ylabel(\"Predicted Wait (min)\")\nax.set_title(\"Actual vs Predicted (OOF)\")\nax.legend()\nax.grid(True)\n\nfinal_rmse = np.sqrt(mean_squared_error(y, oof_pred))\nfinal_mae  = mean_absolute_error(y, oof_pred)\nfinal_r2   = r2_score(y, oof_pred)\nax.text(0.05, 0.92, f\"RMSE={final_rmse:.2f}  MAE={final_mae:.2f}  R²={final_r2:.3f}\",\n        transform=ax.transAxes, color=ORANGE, fontsize=9)\n\n# Feature importance\nax = axes[1]\nfi = pd.Series(best_model.feature_importances_, index=FEATURES).sort_values()\ncolors = [GREEN if v > fi.median() else BLUE for v in fi.values]\nax.barh(fi.index, fi.values, color=colors, alpha=0.85)\nax.set_xlabel(\"Feature Importance\")\nax.set_title(\"Feature Importance\")\nax.grid(True, axis=\"x\")\n\nplt.tight_layout()\nplt.savefig(\"task1_best_model.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"✓ Saved: task1_best_model.png\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 6. SUMMARY\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TASK 1 SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"\"\"\nBest Model:   Gradient Boosting\nValidation:   5-Fold Cross-Validation (n=12,762)\n\nPerformance:\n  RMSE  = {final_rmse:.2f} minutes\n  MAE   = {final_mae:.2f} minutes\n  R²    = {final_r2:.3f}\n\n  Baseline RMSE (predict mean) = {results['Baseline (Mean)']['RMSE mean']:.2f} minutes\n  Improvement over baseline    = {(1 - final_rmse / results['Baseline (Mean)']['RMSE mean'])*100:.1f}%\n\nMetrics Justification:\n  - RMSE: penalizes large errors more heavily (important in clinical setting)\n  - MAE:  interpretable in original units (minutes)\n  - R²:   proportion of variance explained\n\nTop Features (by importance):\nfor feat, imp in fi.sort_values(ascending=False).head(4).items():\n    print(f\"  {feat:<30} {imp:.4f}\")\n\nprint(\"\\n✓ Task 1 complete. Output files saved.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Task 2 — Interval Prediction\nInstead of a single number, produce a **90% prediction interval** — a range that contains the actual wait time 90% of the time. Two methods compared: Residual Bootstrap and Split Conformal Prediction."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CIS432 Optional Project 2 — Task 2: Interval Prediction\nWaiting Time Prediction in Healthcare Operations\n\n# ── Imports ───────────────────────────────────────────────────────────────────\n\n\n# ── Style ─────────────────────────────────────────────────────────────────────\n    \"figure.facecolor\": \"#0f0f0f\", \"axes.facecolor\": \"#1a1a2e\",\n    \"axes.edgecolor\": \"#333\",      \"axes.labelcolor\": \"white\",\n    \"xtick.color\": \"white\",        \"ytick.color\": \"white\",\n    \"text.color\": \"white\",         \"grid.color\": \"#333\",\n    \"grid.linestyle\": \"--\",        \"grid.alpha\": 0.5,\n    \"font.family\": \"monospace\",\n})\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 1. DATA LOADING & FEATURE ENGINEERING (same as Task 1)\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"=\" * 60)\nprint(\"TASK 2 — INTERVAL PREDICTION\")\nprint(\"=\" * 60)\n\nrt   = pd.read_excel(\"data.xlsx\", sheet_name=\"realtime\")\nappt = pd.read_excel(\"data.xlsx\", sheet_name=\"appointments\")\n\nrt[\"datetime\"]        = pd.to_datetime(rt[\"date\"].astype(str)   + \" \" + rt[\"time\"].astype(str))\nappt[\"appt_datetime\"] = pd.to_datetime(appt[\"date\"].astype(str) + \" \" + appt[\"time\"].astype(str))\n\npat = rt[rt[\"entity_type\"] == \"patient\"].copy()\nkey_events = [\"hospital_checkin\",\"bloodwork_checkin\",\"bloodwork_start\",\n              \"bloodwork_end\",\"examination_checkin\",\"examination_start\"]\ndf = pat[pat[\"event\"].isin(key_events)].pivot_table(\n    index=[\"entity_id\",\"date\"], columns=\"event\",\n    values=\"datetime\", aggfunc=\"first\"\n).reset_index()\ndf.columns.name = None\n\ndf[\"wait_minutes\"] = (df[\"examination_start\"] - df[\"examination_checkin\"]).dt.total_seconds() / 60\ndf = df.dropna(subset=[\"wait_minutes\",\"examination_checkin\"])\n\nappt_m = appt.rename(columns={\"patient_id\":\"entity_id\"})\ndf = df.merge(appt_m[[\"entity_id\",\"date\",\"appt_datetime\",\"provider_id\"]],\n              on=[\"entity_id\",\"date\"], how=\"left\")\ndf = df.sort_values(\"examination_checkin\").reset_index(drop=True)\n\ndf[\"checkin_hour\"]             = df[\"examination_checkin\"].dt.hour\ndf[\"checkin_minute\"]           = df[\"examination_checkin\"].dt.minute\ndf[\"day_of_week\"]              = df[\"examination_checkin\"].dt.dayofweek\ndf[\"week\"]                     = df[\"examination_checkin\"].dt.isocalendar().week.astype(int)\ndf[\"bloodwork_duration\"]       = (df[\"bloodwork_end\"] - df[\"bloodwork_start\"]).dt.total_seconds() / 60\ndf[\"total_pre_exam_time\"]      = (df[\"examination_checkin\"] - df[\"hospital_checkin\"]).dt.total_seconds() / 60\ndf[\"early_late_min\"]           = (df[\"examination_checkin\"] - df[\"appt_datetime\"]).dt.total_seconds() / 60\ndf[\"queue_position\"]           = df.groupby(\"date\").cumcount()\ndf[\"provider_patients_so_far\"] = df.groupby([\"date\",\"provider_id\"]).cumcount()\n\nFEATURES = [\"checkin_hour\",\"checkin_minute\",\"day_of_week\",\"week\",\n            \"bloodwork_duration\",\"total_pre_exam_time\",\n            \"early_late_min\",\"queue_position\",\"provider_patients_so_far\"]\nX = df[FEATURES].copy()\ny = df[\"wait_minutes\"].copy()\n\nprint(f\"\\n✓ Dataset ready: {len(X):,} samples\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 2. METHOD A — RESIDUAL BOOTSTRAP INTERVALS\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"─\" * 60)\nprint(\"METHOD A: Residual Bootstrap\")\nprint(\"─\" * 60)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nbase_model = GradientBoostingRegressor(n_estimators=200, max_depth=4,\n                                       learning_rate=0.05, random_state=42)\n\noof_pred  = np.zeros(len(y))\noof_resid = np.zeros(len(y))\n\nfor train_idx, val_idx in kf.split(X):\n    base_model.fit(X.iloc[train_idx], y.iloc[train_idx])\n    oof_pred[val_idx]  = base_model.predict(X.iloc[val_idx])\n    oof_resid[val_idx] = y.iloc[val_idx].values - oof_pred[val_idx]\n\n# Use residuals to build empirical intervals\nalpha = 0.10   # 90% prediction interval\nlo_q  = np.percentile(oof_resid, 100 * alpha / 2)\nhi_q  = np.percentile(oof_resid, 100 * (1 - alpha / 2))\n\nlower_boot = oof_pred + lo_q\nupper_boot = oof_pred + hi_q\n\n# Clip negatives\nlower_boot = np.maximum(lower_boot, 0)\n\n# Evaluate\ncoverage_boot = np.mean((y >= lower_boot) & (y <= upper_boot))\nwidth_boot    = np.mean(upper_boot - lower_boot)\n\nprint(f\"  90% Prediction Interval (Bootstrap)\")\nprint(f\"  Coverage : {coverage_boot:.3f}  (target ≥ 0.90)\")\nprint(f\"  Avg Width: {width_boot:.2f} minutes\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 3. METHOD B — CONFORMAL PREDICTION (Split Conformal, manual)\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"─\" * 60)\nprint(\"METHOD B: Split Conformal Prediction\")\nprint(\"─\" * 60)\n\n# Split: 60% train, 20% calibration, 20% test\nn = len(X)\nidx_all = np.random.RandomState(42).permutation(n)\ntrain_idx = idx_all[:int(0.6*n)]\ncalib_idx = idx_all[int(0.6*n):int(0.8*n)]\ntest_idx  = idx_all[int(0.8*n):]\n\nconf_model = GradientBoostingRegressor(n_estimators=200, max_depth=4,\n                                       learning_rate=0.05, random_state=42)\nconf_model.fit(X.iloc[train_idx], y.iloc[train_idx])\n\n# Calibration nonconformity scores = |y - y_hat|\ncalib_pred   = conf_model.predict(X.iloc[calib_idx])\ncalib_scores = np.abs(y.iloc[calib_idx].values - calib_pred)\n\n# Conformal quantile\nalpha_level = 0.10\nq_level = np.ceil((1 - alpha_level) * (len(calib_idx) + 1)) / len(calib_idx)\nq_level = min(q_level, 1.0)\nconformal_q = np.quantile(calib_scores, q_level)\n\n# Apply to test set\ntest_pred   = conf_model.predict(X.iloc[test_idx])\nlower_mapie = np.maximum(test_pred - conformal_q, 0)\nupper_mapie = test_pred + conformal_q\ny_pred_mapie = test_pred\ny_test_conf  = y.iloc[test_idx].values\n\ncoverage_mapie = np.mean((y_test_conf >= lower_mapie) & (y_test_conf <= upper_mapie))\nwidth_mapie    = np.mean(upper_mapie - lower_mapie)\n\nprint(f\"  90% Prediction Interval (Conformal)\")\nprint(f\"  Coverage : {coverage_mapie:.3f}  (target ≥ 0.90)\")\nprint(f\"  Avg Width: {width_mapie:.2f} minutes\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 4. VISUALISATION\n# ═══════════════════════════════════════════════════════════════════════════════\n\n# --- Plot 1: Interval width vs actual wait ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfig.suptitle(\"Task 2 — Interval Prediction (90% PI)\", color=GREEN, fontsize=14, fontweight=\"bold\")\n\n# Sample 300 points sorted by actual wait for readability\nsort_idx = np.argsort(y_test_conf)[:300]\ny_s     = y_test_conf[sort_idx]\nlo_s    = lower_mapie[sort_idx]\nhi_s    = upper_mapie[sort_idx]\npred_s  = y_pred_mapie[sort_idx]\n\nax = axes[0]\nax.fill_between(range(len(y_s)), lo_s, hi_s, alpha=0.3, color=BLUE, label=\"90% PI\")\nax.plot(range(len(y_s)), pred_s, color=GREEN,  linewidth=1.2, label=\"Predicted\")\nax.scatter(range(len(y_s)), y_s,  color=ORANGE, s=8, alpha=0.6, label=\"Actual\")\nax.set_xlabel(\"Sample (sorted by actual wait)\")\nax.set_ylabel(\"Wait (minutes)\")\nax.set_title(\"Conformal Prediction Intervals\")\nax.legend()\nax.grid(True)\n\n# --- Plot 2: Coverage comparison ---\nax = axes[1]\nmethods   = [\"Bootstrap\\n(Method A)\", \"Conformal\\n(Method B)\"]\ncoverages = [coverage_boot,  coverage_mapie]\nwidths    = [width_boot,     width_mapie]\n\nx = np.arange(2)\nbars = ax.bar(x - 0.2, coverages, width=0.35, color=GREEN,  alpha=0.8, label=\"Coverage\")\nax.set_ylim(0, 1.15)\nax.axhline(0.90, color=RED, linestyle=\"--\", linewidth=1.5, label=\"Target 90%\")\nax.set_xticks(x)\nax.set_xticklabels(methods)\nax.set_ylabel(\"Coverage\")\nax.set_title(\"Coverage vs Width Comparison\")\nax.legend(loc=\"upper left\")\nax.grid(True, axis=\"y\")\n\nax2 = ax.twinx()\nax2.bar(x + 0.2, widths, width=0.35, color=ORANGE, alpha=0.8, label=\"Avg Width (min)\")\nax2.set_ylabel(\"Avg Interval Width (min)\", color=ORANGE)\nax2.tick_params(axis=\"y\", colors=ORANGE)\nax2.legend(loc=\"upper right\")\n\nfor bar, val in zip(bars, coverages):\n    ax.text(bar.get_x() + bar.get_width()/2, val + 0.02,\n            f\"{val:.3f}\", ha=\"center\", fontsize=10, color=GREEN)\n\nplt.tight_layout()\nplt.savefig(\"task2_interval_prediction.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"\\n✓ Saved: task2_interval_prediction.png\")\n\n# --- Plot 2: Interval width distribution ---\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nfig.suptitle(\"Interval Width Analysis\", color=GREEN, fontsize=13, fontweight=\"bold\")\n\naxes[0].hist(upper_mapie - lower_mapie, bins=40, color=BLUE, alpha=0.8, edgecolor=\"#0f0f0f\")\naxes[0].axvline(width_mapie, color=ORANGE, linewidth=2, linestyle=\"--\",\n                label=f\"Mean {width_mapie:.1f} min\")\naxes[0].set_xlabel(\"Interval Width (minutes)\")\naxes[0].set_ylabel(\"Count\")\naxes[0].set_title(\"Distribution of Interval Widths (Conformal)\")\naxes[0].legend()\naxes[0].grid(True)\n\n# Width vs predicted value — do wider intervals occur for longer waits?\naxes[1].scatter(y_pred_mapie, upper_mapie - lower_mapie,\n                alpha=0.1, s=6, color=GREEN)\naxes[1].set_xlabel(\"Predicted Wait (minutes)\")\naxes[1].set_ylabel(\"Interval Width (minutes)\")\naxes[1].set_title(\"Width vs Predicted Value\")\naxes[1].grid(True)\n\nplt.tight_layout()\nplt.savefig(\"task2_width_analysis.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"✓ Saved: task2_width_analysis.png\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 5. SUMMARY\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TASK 2 SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"\"\"\nTwo methods for 90% Prediction Intervals:\n\nMethod A — Residual Bootstrap\n  Coverage : {coverage_boot:.3f}\n  Avg Width: {width_boot:.1f} min\n\nMethod B — Conformal Prediction (MAPIE)\n  Coverage : {coverage_mapie:.3f}\n  Avg Width: {width_mapie:.1f} min\n\nMetrics Justification:\n  - Coverage: proportion of actual values falling inside the interval.\n               Should be ≥ target level (90%). This is the primary metric.\n  - Avg Width: narrower intervals are more actionable. A tradeoff exists\n               between coverage and width — wider intervals are easier to\n               cover but less useful to patients and staff.\n\nRecommendation:\n  Conformal prediction is preferred because it provides a formal\n  coverage guarantee by construction, regardless of model assumptions.\n  Bootstrap intervals rely on residuals being roughly symmetric,\n  which may not hold for skewed waiting time distributions.\n\nClinical Interpretation:\n  A 90% PI of width ~{width_mapie:.0f} min means the system would tell a\n  patient \"your wait will likely be between X and Y minutes\" and\n  be correct 9 out of 10 times. This is more honest and useful\n  than a single point estimate alone.\nprint(\"✓ Task 2 complete.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Task 3 — Quantile Prediction\nEstimate multiple **conditional quantiles** of waiting time simultaneously. Selected quantiles: q10 (optimistic), q25, q50 (median), q75, q90 (SLA anchor)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CIS432 Optional Project 2 — Task 3: Quantile Prediction\nWaiting Time Prediction in Healthcare Operations\n\n# ── Imports ───────────────────────────────────────────────────────────────────\n\n\n# ── Style ─────────────────────────────────────────────────────────────────────\n    \"figure.facecolor\": \"#0f0f0f\", \"axes.facecolor\": \"#1a1a2e\",\n    \"axes.edgecolor\": \"#333\",      \"axes.labelcolor\": \"white\",\n    \"xtick.color\": \"white\",        \"ytick.color\": \"white\",\n    \"text.color\": \"white\",         \"grid.color\": \"#333\",\n    \"grid.linestyle\": \"--\",        \"grid.alpha\": 0.5,\n    \"font.family\": \"monospace\",\n})\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 1. DATA LOADING & FEATURE ENGINEERING\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"=\" * 60)\nprint(\"TASK 3 — QUANTILE PREDICTION\")\nprint(\"=\" * 60)\n\nrt   = pd.read_excel(\"data.xlsx\", sheet_name=\"realtime\")\nappt = pd.read_excel(\"data.xlsx\", sheet_name=\"appointments\")\n\nrt[\"datetime\"]        = pd.to_datetime(rt[\"date\"].astype(str)   + \" \" + rt[\"time\"].astype(str))\nappt[\"appt_datetime\"] = pd.to_datetime(appt[\"date\"].astype(str) + \" \" + appt[\"time\"].astype(str))\n\npat = rt[rt[\"entity_type\"] == \"patient\"].copy()\nkey_events = [\"hospital_checkin\",\"bloodwork_checkin\",\"bloodwork_start\",\n              \"bloodwork_end\",\"examination_checkin\",\"examination_start\"]\ndf = pat[pat[\"event\"].isin(key_events)].pivot_table(\n    index=[\"entity_id\",\"date\"], columns=\"event\",\n    values=\"datetime\", aggfunc=\"first\"\n).reset_index()\ndf.columns.name = None\n\ndf[\"wait_minutes\"] = (df[\"examination_start\"] - df[\"examination_checkin\"]).dt.total_seconds() / 60\ndf = df.dropna(subset=[\"wait_minutes\",\"examination_checkin\"])\n\nappt_m = appt.rename(columns={\"patient_id\":\"entity_id\"})\ndf = df.merge(appt_m[[\"entity_id\",\"date\",\"appt_datetime\",\"provider_id\"]],\n              on=[\"entity_id\",\"date\"], how=\"left\")\ndf = df.sort_values(\"examination_checkin\").reset_index(drop=True)\n\ndf[\"checkin_hour\"]             = df[\"examination_checkin\"].dt.hour\ndf[\"checkin_minute\"]           = df[\"examination_checkin\"].dt.minute\ndf[\"day_of_week\"]              = df[\"examination_checkin\"].dt.dayofweek\ndf[\"week\"]                     = df[\"examination_checkin\"].dt.isocalendar().week.astype(int)\ndf[\"bloodwork_duration\"]       = (df[\"bloodwork_end\"] - df[\"bloodwork_start\"]).dt.total_seconds() / 60\ndf[\"total_pre_exam_time\"]      = (df[\"examination_checkin\"] - df[\"hospital_checkin\"]).dt.total_seconds() / 60\ndf[\"early_late_min\"]           = (df[\"examination_checkin\"] - df[\"appt_datetime\"]).dt.total_seconds() / 60\ndf[\"queue_position\"]           = df.groupby(\"date\").cumcount()\ndf[\"provider_patients_so_far\"] = df.groupby([\"date\",\"provider_id\"]).cumcount()\n\nFEATURES = [\"checkin_hour\",\"checkin_minute\",\"day_of_week\",\"week\",\n            \"bloodwork_duration\",\"total_pre_exam_time\",\n            \"early_late_min\",\"queue_position\",\"provider_patients_so_far\"]\nX = df[FEATURES].copy()\ny = df[\"wait_minutes\"].copy()\n\nprint(f\"\\n✓ Dataset ready: {len(X):,} samples\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 2. QUANTILE SELECTION & JUSTIFICATION\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"─\" * 60)\nprint(\"QUANTILES SELECTED\")\nprint(\"─\" * 60)\n\n# Quantiles chosen for clinical relevance:\n# q=0.10: \"optimistic\" — only 10% of patients wait less than this\n# q=0.25: lower bound — 1st quartile\n# q=0.50: median expectation — fair central estimate\n# q=0.75: upper bound — 3rd quartile\n# q=0.90: \"worst case\" — 90% of patients done by this time (SLA planning)\nQUANTILES = [0.10, 0.25, 0.50, 0.75, 0.90]\nCOLORS    = [BLUE, GREEN, ORANGE, PURPLE, RED]\nLABELS    = {\n    0.10: \"q10 — Optimistic\",\n    0.25: \"q25 — Lower Bound\",\n    0.50: \"q50 — Median\",\n    0.75: \"q75 — Upper Bound\",\n    0.90: \"q90 — Worst Case (SLA)\",\n}\n\nfor q, label in LABELS.items():\n    emp = np.quantile(y, q)\n    print(f\"  {label:<30}  empirical = {emp:.1f} min\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 3. TRAIN ONE QUANTILE REGRESSION MODEL PER QUANTILE (GBR)\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"─\" * 60)\nprint(\"TRAINING QUANTILE MODELS (Gradient Boosting)\")\nprint(\"─\" * 60)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\noof_quantiles = {}   # {q: oof predictions array}\npinball_scores = {}  # {q: mean pinball loss}\n\nfor q in QUANTILES:\n    oof_pred = np.zeros(len(y))\n    fold_losses = []\n\n    for train_idx, val_idx in kf.split(X):\n        model = GradientBoostingRegressor(\n            loss=\"quantile\", alpha=q,\n            n_estimators=200, max_depth=4,\n            learning_rate=0.05, random_state=42\n        )\n        model.fit(X.iloc[train_idx], y.iloc[train_idx])\n        oof_pred[val_idx] = model.predict(X.iloc[val_idx])\n        fold_losses.append(\n            mean_pinball_loss(y.iloc[val_idx], oof_pred[val_idx], alpha=q)\n        )\n\n    oof_quantiles[q]  = oof_pred\n    pinball_scores[q] = np.mean(fold_losses)\n    print(f\"  q={q:.2f}  Pinball Loss = {pinball_scores[q]:.4f}\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 4. COVERAGE CHECK — does q90 actually cover 90% of patients?\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"─\" * 60)\nprint(\"COVERAGE CHECK (actual % of patients below predicted quantile)\")\nprint(\"─\" * 60)\n\nfor q in QUANTILES:\n    actual_coverage = np.mean(y.values <= oof_quantiles[q])\n    print(f\"  q={q:.2f}  target={q:.2f}  actual={actual_coverage:.3f}  \"\n          f\"{'✓' if abs(actual_coverage - q) < 0.03 else '⚠'}\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 5. VISUALISATIONS\n# ═══════════════════════════════════════════════════════════════════════════════\n\n# --- Plot 1: Quantile fan chart sorted by median prediction ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfig.suptitle(\"Task 3 — Quantile Prediction\", color=GREEN, fontsize=14, fontweight=\"bold\")\n\n# Sort 400 samples by q50 for a fan chart\nsort_by_median = np.argsort(oof_quantiles[0.50])[:400]\nx_axis = np.arange(len(sort_by_median))\n\nax = axes[0]\nax.fill_between(x_axis,\n                oof_quantiles[0.10][sort_by_median],\n                oof_quantiles[0.90][sort_by_median],\n                alpha=0.25, color=RED,    label=\"q10–q90 band\")\nax.fill_between(x_axis,\n                oof_quantiles[0.25][sort_by_median],\n                oof_quantiles[0.75][sort_by_median],\n                alpha=0.35, color=BLUE,   label=\"q25–q75 band\")\nax.plot(x_axis, oof_quantiles[0.50][sort_by_median],\n        color=ORANGE, linewidth=1.5, label=\"q50 (median)\")\nax.scatter(x_axis, y.values[sort_by_median],\n           s=5, alpha=0.3, color=\"white\", label=\"Actual\")\nax.set_xlabel(\"Sample (sorted by median prediction)\")\nax.set_ylabel(\"Wait (minutes)\")\nax.set_title(\"Quantile Fan Chart\")\nax.legend(fontsize=8)\nax.grid(True)\n\n# --- Plot 2: Pinball loss per quantile ---\nax = axes[1]\nqs     = list(pinball_scores.keys())\nlosses = list(pinball_scores.values())\ncolors = [BLUE, GREEN, ORANGE, PURPLE, RED]\n\nbars = ax.bar([str(q) for q in qs], losses, color=colors, alpha=0.85, edgecolor=\"#0f0f0f\")\nfor bar, val in zip(bars, losses):\n    ax.text(bar.get_x() + bar.get_width()/2, val + 0.1,\n            f\"{val:.2f}\", ha=\"center\", fontsize=10, color=\"white\")\nax.set_xlabel(\"Quantile\")\nax.set_ylabel(\"Pinball Loss (lower = better)\")\nax.set_title(\"Pinball Loss by Quantile\")\nax.grid(True, axis=\"y\")\n\nplt.tight_layout()\nplt.savefig(\"task3_quantile_prediction.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"\\n✓ Saved: task3_quantile_prediction.png\")\n\n# --- Plot 2: Calibration plot — predicted quantile vs actual coverage ---\nfig, ax = plt.subplots(figsize=(7, 5))\nfig.suptitle(\"Quantile Calibration\", color=GREEN, fontsize=13, fontweight=\"bold\")\n\ntarget_coverages = QUANTILES\nactual_coverages = [np.mean(y.values <= oof_quantiles[q]) for q in QUANTILES]\n\nax.plot([0, 1], [0, 1], \"--\", color=\"white\", linewidth=1.5, label=\"Perfect calibration\")\nax.scatter(target_coverages, actual_coverages, s=120,\n           color=colors, zorder=5, edgecolors=\"white\", linewidths=0.8)\nfor q, act, col in zip(target_coverages, actual_coverages, colors):\n    ax.annotate(f\"q{int(q*100)}\", (q, act),\n                textcoords=\"offset points\", xytext=(8, 4),\n                fontsize=9, color=col)\nax.set_xlabel(\"Target Coverage (quantile)\")\nax.set_ylabel(\"Actual Coverage\")\nax.set_title(\"Calibration: Target vs Actual Coverage\")\nax.legend()\nax.grid(True)\nax.set_xlim(0, 1); ax.set_ylim(0, 1)\n\nplt.tight_layout()\nplt.savefig(\"task3_calibration.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"✓ Saved: task3_calibration.png\")\n\n# ═══════════════════════════════════════════════════════════════════════════════\n# 6. SUMMARY\n# ═══════════════════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TASK 3 SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"\"\"\nModel: Gradient Boosting Quantile Regression\nValidation: 5-Fold Cross-Validation\nEvaluation Metric: Pinball Loss (per quantile)\n\nQuantiles & Pinball Loss:\"\"\")\nfor q, loss in pinball_scores.items():\n    print(f\"  q={q:.2f}  {LABELS[q]:<30}  Pinball = {loss:.4f}\")\n\nprint(f\"\"\"\nMetric Justification:\n  - Pinball Loss (also called quantile loss) is the standard metric\n    for evaluating quantile regression. For quantile q, it penalizes\n    overestimates by (1-q) and underestimates by q.\n  - A lower pinball loss at a given quantile means the model is\n    better calibrated at that level.\n  - Calibration plot confirms the model's predicted quantiles\n    align closely with empirical coverage rates.\n\nClinical Relevance of Selected Quantiles:\n  q10 — Tells staff: \"even in the best case, expect ~X min wait\"\n  q50 — Most likely outcome; fair expectation to set for patients\n  q75 — Upper bound for scheduling buffers\n  q90 — Service level anchor: 90% of patients seen within this time.\n         Useful for operational targets and staffing decisions.\n\nKey Advantage over Task 1 & 2:\n  Quantile regression reveals the full shape of the conditional\n  distribution — not just the center (Task 1) or a single interval\n  (Task 2). Decision-makers can choose which quantile matters most\n  for their risk tolerance.\nprint(\"✓ Task 3 complete.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Task 4 — Dynamic Prediction Over Time\nAfter check-in, new information accumulates as the patient waits. We retrain one model per time snapshot (t = 0, 5, 10, 15, 20 minutes) using dynamic queue features available at that moment."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"figure.facecolor\": \"#0f0f0f\", \"axes.facecolor\": \"#1a1a2e\",\n    \"axes.edgecolor\": \"#333\", \"axes.labelcolor\": \"white\",\n    \"xtick.color\": \"white\", \"ytick.color\": \"white\",\n    \"text.color\": \"white\", \"grid.color\": \"#333\",\n    \"grid.linestyle\": \"--\", \"grid.alpha\": 0.5,\n    \"font.family\": \"monospace\",\n})\n\nprint(\"=\"*60)\nprint(\"TASK 4 — DYNAMIC PREDICTION OVER TIME\")\nprint(\"=\"*60)\n\nrt   = pd.read_excel(\"data.xlsx\", sheet_name=\"realtime\")\nappt = pd.read_excel(\"data.xlsx\", sheet_name=\"appointments\")\n\nrt[\"datetime\"]        = pd.to_datetime(rt[\"date\"].astype(str) + \" \" + rt[\"time\"].astype(str))\nappt[\"appt_datetime\"] = pd.to_datetime(appt[\"date\"].astype(str) + \" \" + appt[\"time\"].astype(str))\n\npat = rt[rt[\"entity_type\"] == \"patient\"].copy()\nprov = rt[rt[\"entity_type\"] == \"provider\"].copy()\n\nkey_events = [\"hospital_checkin\",\"bloodwork_checkin\",\"bloodwork_start\",\n              \"bloodwork_end\",\"examination_checkin\",\"examination_start\"]\ndf = pat[pat[\"event\"].isin(key_events)].pivot_table(\n    index=[\"entity_id\",\"date\"], columns=\"event\",\n    values=\"datetime\", aggfunc=\"first\"\n).reset_index()\ndf.columns.name = None\n\ndf[\"wait_minutes\"] = (df[\"examination_start\"] - df[\"examination_checkin\"]).dt.total_seconds() / 60\ndf = df.dropna(subset=[\"wait_minutes\",\"examination_checkin\"])\n\nappt_m = appt.rename(columns={\"patient_id\":\"entity_id\"})\ndf = df.merge(appt_m[[\"entity_id\",\"date\",\"appt_datetime\",\"provider_id\"]],\n              on=[\"entity_id\",\"date\"], how=\"left\")\ndf = df.sort_values([\"date\",\"examination_checkin\"]).reset_index(drop=True)\n\n# Base features\ndf[\"checkin_hour\"]             = df[\"examination_checkin\"].dt.hour\ndf[\"checkin_minute\"]           = df[\"examination_checkin\"].dt.minute\ndf[\"day_of_week\"]              = df[\"examination_checkin\"].dt.dayofweek\ndf[\"week\"]                     = df[\"examination_checkin\"].dt.isocalendar().week.astype(int)\ndf[\"bloodwork_duration\"]       = (df[\"bloodwork_end\"] - df[\"bloodwork_start\"]).dt.total_seconds() / 60\ndf[\"total_pre_exam_time\"]      = (df[\"examination_checkin\"] - df[\"hospital_checkin\"]).dt.total_seconds() / 60\ndf[\"early_late_min\"]           = (df[\"examination_checkin\"] - df[\"appt_datetime\"]).dt.total_seconds() / 60\ndf[\"queue_position\"]           = df.groupby(\"date\").cumcount()\ndf[\"provider_patients_so_far\"] = df.groupby([\"date\",\"provider_id\"]).cumcount()\n\nprint(f\"\\n✓ Base dataset: {len(df):,} patients\")\n\n# ── Provider room lookup table (vectorised) ──────────────────────────────────\nprov_room = prov[prov[\"event\"].isin([\"provider_entered_room\",\"provider_left_room\"])].copy()\nprov_room = prov_room.sort_values(\"datetime\")\n\n# ── Build snapshot rows efficiently ─────────────────────────────────────────\nSNAPSHOTS = [0, 5, 10, 15, 20]\nBASE_FEATS = [\"checkin_hour\",\"checkin_minute\",\"day_of_week\",\"week\",\n              \"bloodwork_duration\",\"total_pre_exam_time\",\"early_late_min\",\n              \"queue_position\",\"provider_patients_so_far\"]\n\nprint(\"\\nBuilding snapshot rows...\")\nall_rows = []\n\n# Pre-index exam events by date for fast lookup\ndf_by_date = {d: grp for d, grp in df.groupby(\"date\")}\nprov_by_pid_date = {(p, d): grp for (p, d), grp in prov_room.groupby([\"entity_id\",\"date\"])}\n\nfor _, pat_row in df.iterrows():\n    ec  = pat_row[\"examination_checkin\"]\n    es  = pat_row[\"examination_start\"]\n    aw  = pat_row[\"wait_minutes\"]\n    pid = pat_row[\"provider_id\"]\n    d   = pat_row[\"date\"]\n    day_df = df_by_date.get(d, pd.DataFrame())\n\n    for t in SNAPSHOTS:\n        snap = ec + pd.Timedelta(minutes=t)\n        if snap >= es:\n            continue\n\n        remaining = aw - t\n\n        # Queue dynamics\n        served_ahead = int(((day_df[\"examination_checkin\"] < ec) &\n                            (day_df[\"examination_start\"]  <= snap)).sum())\n        still_ahead  = int(((day_df[\"examination_checkin\"] < ec) &\n                            (day_df[\"examination_start\"]  >  snap)).sum())\n\n        # Provider status\n        provider_busy = 0\n        prov_in_room_dur = 0.0\n        if not pd.isna(pid):\n            key = (int(pid), d)\n            pev = prov_by_pid_date.get(key, pd.DataFrame())\n            if len(pev):\n                pev_before = pev[pev[\"datetime\"] <= snap]\n                if len(pev_before):\n                    last_ev = pev_before.iloc[-1]\n                    if last_ev[\"event\"] == \"provider_entered_room\":\n                        provider_busy = 1\n                        prov_in_room_dur = (snap - last_ev[\"datetime\"]).total_seconds() / 60\n\n        row = {feat: pat_row[feat] for feat in BASE_FEATS}\n        row.update({\n            \"entity_id\": pat_row[\"entity_id\"],\n            \"actual_wait\": aw,\n            \"t_elapsed\": t,\n            \"remaining_wait\": remaining,\n            \"patients_served_ahead\": served_ahead,\n            \"patients_still_waiting_ahead\": still_ahead,\n            \"provider_busy_at_t\": provider_busy,\n            \"provider_in_room_duration\": prov_in_room_dur,\n        })\n        all_rows.append(row)\n\ndyn = pd.DataFrame(all_rows)\ndyn = dyn[dyn[\"remaining_wait\"] > 0].reset_index(drop=True)\n\nprint(f\"✓ Dynamic dataset: {len(dyn):,} snapshot rows\")\nfor t in SNAPSHOTS:\n    n = (dyn[\"t_elapsed\"] == t).sum()\n    print(f\"  t={t:>2} min: {n:,} samples\")\n\n# ── Train one model per snapshot ─────────────────────────────────────────────\nprint(\"\\n\" + \"─\"*60)\nprint(\"TRAINING (5-Fold CV per snapshot)\")\nprint(\"─\"*60)\n\nDYN_FEATS = BASE_FEATS + [\"t_elapsed\",\"patients_served_ahead\",\n                           \"patients_still_waiting_ahead\",\n                           \"provider_busy_at_t\",\"provider_in_room_duration\"]\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nresults = {}\n\nfor t in SNAPSHOTS:\n    sub = dyn[dyn[\"t_elapsed\"] == t]\n    Xt  = sub[DYN_FEATS].fillna(0)\n    yt  = sub[\"remaining_wait\"]\n    oof = np.zeros(len(yt))\n    for tr, va in kf.split(Xt):\n        m = GradientBoostingRegressor(n_estimators=150, max_depth=4,\n                                      learning_rate=0.05, random_state=42)\n        m.fit(Xt.iloc[tr], yt.iloc[tr])\n        oof[va] = m.predict(Xt.iloc[va])\n    rmse = np.sqrt(mean_squared_error(yt, oof))\n    mae  = mean_absolute_error(yt, oof)\n    r2   = r2_score(yt, oof)\n    results[t] = {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n    print(f\"  t={t:>2} min  RMSE={rmse:.2f}  MAE={mae:.2f}  R²={r2:.3f}\")\n\n# ── Plots ─────────────────────────────────────────────────────────────────────\nts    = list(results.keys())\nrmses = [results[t][\"RMSE\"] for t in ts]\nmaes  = [results[t][\"MAE\"]  for t in ts]\nr2s   = [results[t][\"R2\"]   for t in ts]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfig.suptitle(\"Task 4 — Dynamic Prediction: Performance Over Time\",\n             color=GREEN, fontsize=14, fontweight=\"bold\")\n\nfor ax, vals, color, label in zip(\n    axes,\n    [rmses, maes, r2s],\n    [RED, ORANGE, GREEN],\n    [\"RMSE (minutes)\", \"MAE (minutes)\", \"R²\"]\n):\n    ax.plot(ts, vals, color=color, marker=\"o\", linewidth=2, markersize=9)\n    for t, v in zip(ts, vals):\n        ax.text(t, v + (max(vals)-min(vals))*0.03, f\"{v:.2f}\",\n                ha=\"center\", fontsize=9, color=color)\n    ax.set_xlabel(\"Minutes Elapsed Since Check-in\")\n    ax.set_ylabel(label)\n    ax.set_title(label + \" vs Elapsed Time\")\n    ax.set_xticks(ts)\n    ax.grid(True)\n\nplt.tight_layout()\nplt.savefig(\"task4_dynamic_performance.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"\\n✓ Saved: task4_dynamic_performance.png\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TASK 4 SUMMARY\")\nprint(\"=\"*60)\nprint(f\"\"\"\nDynamic features added at each snapshot:\n  - t_elapsed                    : minutes already waited\n  - patients_served_ahead        : patients ahead now done\n  - patients_still_waiting_ahead : patients ahead still in queue\n  - provider_busy_at_t           : is provider currently in a room?\n  - provider_in_room_duration    : how long has provider been in room?\n\nPerformance (RMSE on remaining wait):\"\"\")\nfor t in SNAPSHOTS:\n    print(f\"  t={t:>2} min  RMSE={results[t]['RMSE']:.2f}  R²={results[t]['R2']:.3f}\")\n\nimp = (results[0]['RMSE'] - results[20]['RMSE']) / results[0]['RMSE'] * 100\nprint(f\"\\n  RMSE improvement t=0 → t=20: {imp:.1f}%\")\nprint(\"\\n✓ Task 4 complete.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Task 5 — Comparison and Reflection\nSide-by-side comparison of all four approaches, with deployment recommendation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CIS432 Optional Project 2 — Task 5: Comparison and Reflection\n\n    \"figure.facecolor\": \"#0f0f0f\", \"axes.facecolor\": \"#1a1a2e\",\n    \"axes.edgecolor\": \"#333\", \"axes.labelcolor\": \"white\",\n    \"xtick.color\": \"white\", \"ytick.color\": \"white\",\n    \"text.color\": \"white\", \"grid.color\": \"#333\",\n    \"grid.linestyle\": \"--\", \"grid.alpha\": 0.5,\n    \"font.family\": \"monospace\",\n})\n\nprint(\"=\"*60)\nprint(\"TASK 5 — COMPARISON AND REFLECTION\")\nprint(\"=\"*60)\n\n# ── Summary data from Tasks 1–4 ──────────────────────────────────────────────\ncomparison = {\n    \"Task 1\\nPoint\":     {\"RMSE\": 30.39, \"MAE\": 22.77, \"Coverage\": None,  \"Width\": None,   \"Interpretable\": 4, \"Actionable\": 3},\n    \"Task 2\\nInterval\":  {\"RMSE\": None,  \"MAE\": None,  \"Coverage\": 0.899, \"Width\": 86.5,   \"Interpretable\": 4, \"Actionable\": 4},\n    \"Task 3\\nQuantile\":  {\"RMSE\": None,  \"MAE\": None,  \"Coverage\": None,  \"Width\": None,   \"Interpretable\": 5, \"Actionable\": 5},\n    \"Task 4\\nDynamic\":   {\"RMSE\": 27.65, \"MAE\": 20.58, \"Coverage\": None,  \"Width\": None,   \"Interpretable\": 3, \"Actionable\": 5},\n}\n\n# ── Plot 1: Multi-panel comparison ───────────────────────────────────────────\nfig = plt.figure(figsize=(16, 10))\nfig.suptitle(\"Task 5 — Approach Comparison\", color=GREEN, fontsize=15, fontweight=\"bold\")\ngs = gridspec.GridSpec(2, 3, figure=fig, hspace=0.45, wspace=0.35)\n\nlabels = list(comparison.keys())\ncolors = [GREEN, ORANGE, BLUE, PURPLE]\n\n# Panel 1: RMSE (Tasks 1 & 4 only)\nax1 = fig.add_subplot(gs[0, 0])\nrmse_tasks  = [\"Task 1\\nPoint\", \"Task 4\\nDynamic\"]\nrmse_vals   = [30.39, 27.65]\nrmse_colors = [GREEN, PURPLE]\nbars = ax1.bar(rmse_tasks, rmse_vals, color=rmse_colors, alpha=0.85, edgecolor=\"#0f0f0f\")\nfor bar, val in zip(bars, rmse_vals):\n    ax1.text(bar.get_x() + bar.get_width()/2, val + 0.3,\n             f\"{val:.2f}\", ha=\"center\", fontsize=11, color=\"white\", fontweight=\"bold\")\nax1.set_ylabel(\"RMSE (minutes)\")\nax1.set_title(\"Point Accuracy\\n(lower = better)\")\nax1.grid(True, axis=\"y\")\nax1.set_ylim(0, 38)\n\n# Panel 2: Interval coverage vs width\nax2 = fig.add_subplot(gs[0, 1])\nax2.bar([\"Task 2\\nInterval\"], [0.899], color=ORANGE, alpha=0.85, edgecolor=\"#0f0f0f\", label=\"Coverage\")\nax2.axhline(0.90, color=RED, linestyle=\"--\", linewidth=1.5, label=\"Target 90%\")\nax2.set_ylabel(\"Coverage\")\nax2.set_ylim(0.85, 0.95)\nax2.set_title(\"Interval Coverage\\n(target ≥ 0.90)\")\nax2.legend(fontsize=8)\nax2.grid(True, axis=\"y\")\nax2_r = ax2.twinx()\nax2_r.bar([\"Task 2\\nInterval\"], [86.5], color=ORANGE, alpha=0.3, width=0.4)\nax2_r.set_ylabel(\"Avg Width (min)\", color=ORANGE)\nax2_r.tick_params(axis=\"y\", colors=ORANGE)\n\n# Panel 3: Quantile coverage (calibration)\nax3 = fig.add_subplot(gs[0, 2])\nqs      = [0.10, 0.25, 0.50, 0.75, 0.90]\nactuals = [0.115, 0.254, 0.505, 0.747, 0.894]\nq_colors= [BLUE, GREEN, ORANGE, PURPLE, RED]\nax3.plot([0,1],[0,1],\"--\",color=\"white\",linewidth=1.2,label=\"Perfect\")\nax3.scatter(qs, actuals, s=100, color=q_colors, zorder=5, edgecolors=\"white\")\nfor q, a in zip(qs, actuals):\n    ax3.annotate(f\"q{int(q*100)}\", (q, a), xytext=(6, 4),\n                 textcoords=\"offset points\", fontsize=8, color=\"white\")\nax3.set_xlabel(\"Target Quantile\")\nax3.set_ylabel(\"Actual Coverage\")\nax3.set_title(\"Quantile Calibration\\n(Task 3)\")\nax3.legend(fontsize=8)\nax3.grid(True)\n\n# Panel 4: Dynamic RMSE over time\nax4 = fig.add_subplot(gs[1, 0])\nt_vals    = [0, 5, 10, 15, 20]\nrmse_dyn  = [29.25, 28.86, 28.33, 27.93, 27.65]\nax4.plot(t_vals, rmse_dyn, color=PURPLE, marker=\"o\", linewidth=2, markersize=8)\nfor t, r in zip(t_vals, rmse_dyn):\n    ax4.text(t, r+0.1, f\"{r:.1f}\", ha=\"center\", fontsize=8, color=PURPLE)\nax4.set_xlabel(\"Minutes Elapsed\")\nax4.set_ylabel(\"RMSE (minutes)\")\nax4.set_title(\"Dynamic Accuracy\\nImproves Over Time\")\nax4.set_xticks(t_vals)\nax4.grid(True)\n\n# Panel 5: Interpretability vs Actionability radar-style bar\nax5 = fig.add_subplot(gs[1, 1])\ndims   = [\"Interpretable\", \"Actionable\"]\ntask_names = [\"Point\",\"Interval\",\"Quantile\",\"Dynamic\"]\ntask_cols  = [GREEN, ORANGE, BLUE, PURPLE]\nx = np.arange(len(dims))\nwidth = 0.2\nfor i, (tname, tcol) in enumerate(zip(task_names, task_cols)):\n    key = f\"Task {'1' if tname=='Point' else '2' if tname=='Interval' else '3' if tname=='Quantile' else '4'}\\n{tname}\"\n    vals = [comparison[key][\"Interpretable\"], comparison[key][\"Actionable\"]]\n    ax5.bar(x + i*width, vals, width, color=tcol, alpha=0.85, label=tname, edgecolor=\"#0f0f0f\")\nax5.set_xticks(x + width*1.5)\nax5.set_xticklabels(dims)\nax5.set_ylabel(\"Score (1–5)\")\nax5.set_title(\"Interpretability &\\nActionability\")\nax5.legend(fontsize=8, loc=\"lower right\")\nax5.set_ylim(0, 6)\nax5.grid(True, axis=\"y\")\n\n# Panel 6: Recommendation summary text\nax6 = fig.add_subplot(gs[1, 2])\nax6.axis(\"off\")\nrec_text = (\n    \"DEPLOYMENT RECOMMENDATION\\n\\n\"\n    \"Primary: Task 3 (Quantile)\\n\"\n    \"→ q50: patient-facing ETA\\n\"\n    \"→ q90: staff SLA target\\n\\n\"\n    \"Secondary: Task 4 (Dynamic)\\n\"\n    \"→ Updates prediction as\\n\"\n    \"  patient continues waiting\\n\\n\"\n    \"Task 2 (Interval) useful for\\n\"\n    \"communicating uncertainty\\n\\n\"\n    \"Task 1 as internal baseline\"\n)\nax6.text(0.05, 0.95, rec_text, transform=ax6.transAxes,\n         fontsize=10, verticalalignment=\"top\", color=\"white\",\n         bbox=dict(boxstyle=\"round\", facecolor=\"#1a1a2e\", edgecolor=GREEN, linewidth=1.5))\n\nplt.savefig(\"task5_comparison.png\", dpi=150, bbox_inches=\"tight\")\nplt.close()\nprint(\"✓ Saved: task5_comparison.png\")\n\n# ── Print summary ─────────────────────────────────────────────────────────────\nprint(f\"\"\"\n{\"=\"*60}\nTASK 5 SUMMARY\n{\"=\"*60}\n\nCOMPARISON OF APPROACHES\n─────────────────────────────────────────────────────────────\nTask 1 — Point Prediction\n  • Output   : single predicted wait (e.g., \"37 minutes\")\n  • Metric   : RMSE = 30.4 min, MAE = 22.8 min, R² = 0.311\n  • Insight  : fast baseline; shows key drivers (provider load,\n               queue position, arrival timing)\n  • Limit    : conveys false precision — no sense of uncertainty\n\nTask 2 — Interval Prediction\n  • Output   : 90% prediction interval (e.g., \"14 – 100 min\")\n  • Metric   : Coverage = 89.9%, Avg Width = 86.5 min\n  • Insight  : honest about uncertainty; useful for risk-averse\n               communication to patients and administrators\n  • Limit    : one fixed coverage level; wide intervals may\n               frustrate patients who want a precise answer\n\nTask 3 — Quantile Prediction\n  • Output   : multiple quantiles (q10, q25, q50, q75, q90)\n  • Metric   : Pinball loss per quantile; all well-calibrated\n  • Insight  : exposes full conditional distribution; different\n               stakeholders use different quantiles (patients → q50,\n               schedulers → q75, SLA monitoring → q90)\n  • Limit    : slightly harder to explain to non-technical users\n\nTask 4 — Dynamic Prediction\n  • Output   : updated remaining-wait prediction every 5 minutes\n  • Metric   : RMSE improves from 29.3 (t=0) to 27.7 (t=20), ↓5.5%\n  • Insight  : captures real-time queue state; reduces anxiety by\n               giving patients a live updated ETA\n  • Limit    : requires real-time data pipeline; model complexity\n               increases (one model per snapshot)\n\nTRADEOFFS\n─────────────────────────────────────────────────────────────\n  Precision vs Honesty  : Task 1 (precise) vs Task 2/3 (honest)\n  Complexity vs Utility : Task 4 (complex pipeline, highest value)\n  Flexibility           : Task 3 lets each stakeholder choose level\n\nDEPLOYMENT RECOMMENDATION\n─────────────────────────────────────────────────────────────\n  Recommended: Task 3 (Quantile) + Task 4 (Dynamic) combined\n\n  Rationale:\n  - Quantile model gives multiple output levels at check-in time.\n    q50 shown to patients on a display screen as expected wait;\n    q90 used internally for staffing targets and SLA tracking.\n  - Dynamic model updates the q50 estimate every 5 minutes as the\n    patient waits, reducing uncertainty and managing expectations.\n  - Interval prediction (Task 2) folded in by showing q25–q75 as\n    a visual band around the point estimate.\n  - Task 1 retained as an internal benchmark only.\n\n  Rollout plan:\n  1. Pilot with one provider team for 4 weeks\n  2. Collect feedback from patients and staff\n  3. Monitor coverage and RMSE on live data weekly\n  4. Retrain models monthly as new data accumulates\nprint(\"✓ Task 5 complete.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Conclusion\n\nThis project developed and evaluated four complementary predictive approaches for examination waiting time at a cancer hospital. The recommended production system combines **quantile regression** (Task 3) for multi-stakeholder outputs at check-in with **dynamic updating** (Task 4) to provide live predictions as patients wait. Together they balance accuracy, honesty about uncertainty, and operational usefulness.\n\n*CIS432 — Optional Project 2*"
  }
 ]
}